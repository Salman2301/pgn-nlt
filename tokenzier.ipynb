{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spacy\n",
    "# !pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salman/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Token\n",
    "\n",
    "# Create a blank English model\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_token(label, words):\n",
    "  token_label = f\"is_{label}\"\n",
    "  pipe_name = f\"label_{label}\"\n",
    "  matcherName = label.upper()\n",
    "  # Register the custom extension attribute\n",
    "  Token.set_extension(token_label, default=False, force=True)\n",
    "\n",
    "  # Define patterns for pieces using spaCy's pattern syntax\n",
    "  matcher = Matcher(nlp.vocab)\n",
    "  patterns = [\n",
    "    [{\"ORTH\": {\"in\": word.split()}}] for word in words\n",
    "  ]\n",
    "\n",
    "  # Add patterns to the matcher\n",
    "  for i, pattern in enumerate(patterns, start=1):\n",
    "    matcher.add(f\"{matcherName}_PATTERN_{i}\", [pattern])\n",
    "\n",
    "  # Define a custom component to apply the matcher and label tokens\n",
    "  @spacy.Language.component(pipe_name)\n",
    "  def label_token(doc):\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "      span = doc[start:end]\n",
    "      for token in span:\n",
    "        token._.set(token_label, True)\n",
    "    return doc\n",
    "\n",
    "  # Add the component to the pipeline\n",
    "  nlp.add_pipe(pipe_name, last=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_token(label=\"place\", words=[\n",
    "  \"a1\", \"b1\", \"c1\", \"d1\", \"e1\", \"f1\", \"g1\", \"h1\",\n",
    "  \"a2\", \"b2\", \"c2\", \"d2\", \"e2\", \"f2\", \"g2\", \"h2\",\n",
    "  \"a3\", \"b3\", \"c3\", \"d3\", \"e3\", \"f3\", \"g3\", \"h3\",\n",
    "  \"a4\", \"b4\", \"c4\", \"d4\", \"e4\", \"f4\", \"g4\", \"h4\",\n",
    "  \"a5\", \"b5\", \"c5\", \"d5\", \"e5\", \"f5\", \"g5\", \"h5\",\n",
    "  \"a6\", \"b6\", \"c6\", \"d6\", \"e6\", \"f6\", \"g6\", \"h6\",\n",
    "  \"a7\", \"b7\", \"c7\", \"d7\", \"e7\", \"f7\", \"g7\", \"h7\",\n",
    "  \"a8\", \"b8\", \"c8\", \"d8\", \"e8\", \"f8\", \"g8\", \"h8\",\n",
    "])\n",
    "\n",
    "setup_token(label=\"piece\", words=[\"king\", \"queen\", \"bishop\", \"knight\", \"rook\", \"pawn\"])\n",
    "setup_token(label=\"action\", words=[\"to\", \"move\", \"moves\", \"capture\",\"captures\", \"en passant\", \"promote\",\"promotes\"])\n",
    "setup_token(label=\"color\", words=[\"white\", \"black\"])\n",
    "setup_token(label=\"flag\", words=[\"check\", \"checkmate\"])\n",
    "\n",
    "# long side castle is not tagged?\n",
    "# setup_token(label=\"castle\", words=[\"long side castle\", \"king side castle\", \"castle\", \"short side castle\", \"queen side castle\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing token white moves pawn to e7 with check : \n",
      "Color: white\n",
      "Action: moves\n",
      "Piece: pawn\n",
      "Action: to\n",
      "Place: e7\n",
      "Flag: check\n",
      "\n",
      "\n",
      "\n",
      "Printing token long side castle with check : \n",
      "Flag: check\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process a text and check the custom attribute\n",
    "# text = \"White moves pawn to e7\"\n",
    "\n",
    "def log_token(text):\n",
    "  doc = nlp(text.lower())\n",
    "  print(f\"Printing token {doc} : \")\n",
    "\n",
    "  for token in doc:\n",
    "    if token._.is_color:\n",
    "      print(f\"Color: {token.text}\")\n",
    "    if token._.is_action:\n",
    "      print(f\"Action: {token.text}\")\n",
    "    if token._.is_place:\n",
    "      print(f\"Place: {token.text}\")\n",
    "    if token._.is_piece:\n",
    "      print(f\"Piece: {token.text}\")\n",
    "    if token._.is_flag:\n",
    "      print(f\"Flag: {token.text}\")\n",
    "  \n",
    "  print(\"\\n\\n\")\n",
    "\n",
    "log_token(\"White moves pawn to e7 with check\")\n",
    "log_token(\"Long side castle with check\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
